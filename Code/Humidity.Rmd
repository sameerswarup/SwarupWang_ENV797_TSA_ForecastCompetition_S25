---
title: "SwarupWang_ForecastCompetition"
author: "Lucy Wang"
date: "2025-03-31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(readxl)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(smooth)
library(zoo)
library(kableExtra)
```

# Data Wrangling

Transform the hourly data into daily data:

Cleaned Dataframes: daily_load, daily temp, daily_humidity

```{r}
# Load the demand excel file
load_df <- read_excel("./Data/load.xlsx")
  
daily_load <- load_df %>% 
  group_by(meter_id, date) %>%
  summarize(
    daily_avg = mean(c_across(1:24), na.rm = TRUE),
    .groups   = "drop"
  )

# Load the temperature file
temp_df <- read_excel("./Data/temperature.xlsx")

daily_temp <- temp_df[1:3] %>% 
  group_by(date) %>%
  summarize(
    daily_avg = mean(t_ws1, na.rm = TRUE),
    .groups   = "drop"
  )

# Load the humidity file
humidity_df <- read_excel("./Data/relative_humidity.xlsx")

daily_humidity <- humidity_df[1:3] %>% 
  group_by(date) %>%
  summarize(
    daily_avg = mean(rh_ws1, na.rm = TRUE),
    .groups   = "drop"
  )
```

## Initial Plots

```{r}

TS_Plot <- 
  ggplot(daily_load, aes(x=date, y=daily_avg)) +
      geom_line()
plot(TS_Plot)

#ACF and PACF plots
par(mfrow=c(1,2))
ACF_Plot <- Acf(daily_load$daily_avg, lag = 40, plot = TRUE)
PACF_Plot <- Pacf(daily_load$daily_avg, lag = 40)
par(mfrow=c(1,1))
```

## Create a Time Series Object

After processing your dataset, use the msts() function to create a time series object. You need to use msts() instead of ts() because your daily data has more than one seasonal component.

```{r}
# Create time series for load 
load_ts <- msts(daily_load$daily_avg, 
                seasonal.periods =c(7,365.25), 
                start=c(2005,1,1))

# Create time series for temperature 
temp_ts <- msts(daily_temp$daily_avg, 
                seasonal.periods =c(7,365.25), 
                start=c(2005,1,1))

# Create time series for humidity
humidity_ts <- msts(daily_humidity$daily_avg, 
                seasonal.periods =c(7,365.25), 
                start=c(2005,1,1))
```


# Training, Model Fitting, and Forecasting

The dataset spans from January 1, 2005, to December 31, 2010. For model training, use data from January 1, 2005, to December 31, 2009. Once you have processed the data, fit models using this training period. To evaluate model performance, use the fitted models to forecast daily demand for January 1, 2010, to February 28, 2010, as a validation set. Assess which model(s) provide accurate forecasts.

After selecting the best-performing model(s), re-train the model using the full dataset from January 1, 2005, to December 31, 2010. Use this updated model to generate forecasts for January 1, 2011, to February 28, 2011. The final forecasts will be submitted as part of the competition.

## Decomposing both time series objects
```{r}
load_ts %>% mstl() %>%
  autoplot()

temp_ts %>% mstl() %>%
  autoplot()

humidity_ts %>% mstl() %>%
  autoplot()
```

## Forecasting Daily Load 
```{r}
#create subsets for training/testing purpose
n_for = 365
ts_load_train <- subset(load_ts,
                        end = length(load_ts)-n_for)

ts_load_test <- subset(load_ts,
                       start = length(load_ts)-n_for)

ts_temp_train <- subset(temp_ts,
                        end = length(temp_ts)-n_for)

ts_temp_test <- subset(temp_ts,
                       start = length(temp_ts)-n_for)

ts_humidity_train <- subset(humidity_ts,
                        end = length(humidity_ts)-n_for)

ts_humidity_test <- subset(humidity_ts,
                       start = length(humidity_ts)-n_for)
```

### Model 1: STL + ETS

```{r ETS, echo=TRUE, message=FALSE, warning=FALSE}
#Fit and forecast STL + ETS model to data
ETS_fit <-  stlf(ts_temp_train,h=365)

#Plot foresting results
autoplot(ETS_fit) + ylab("Temperature")

#Plot model + observed data
autoplot(temp_ts) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Temperature")+
  theme_minimal()

```

### Model 2: ARIMA + FOURIER terms

```{r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
#Fit arima model with fourier terms as exogenous regressors
# seasonal = FALSE is the same as P=D=Q=0
# play with K by changing it to K=c(2,2), K=c(2,4), K=c(2,6), etc. The higher the K the longer it will take to converge, because R will try more models.

ARIMA_Four_fit <- auto.arima(ts_humidity_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_humidity_train, 
                                          K=c(2,12))
                             )

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(ts_humidity_train,
                                        K=c(2,12),
                                        h=366),
                           h=366
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_for) + ylab("Humidity")

#Plot model + observed data
autoplot(humidity_ts) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Humidity")+
  theme_minimal()

# Accuracy test
ARIMA_scores <- accuracy(ARIMA_Four_for$mean,ts_humidity_test)
ARIMA_scores
```
### Model 3: TBATS

BATS is Exponential smoothing state space model with **B**ox-Cox transformation, **A**RMA errors, **T**rend and **S**easonal components.
TBATS is a trigonometric seasonal variation of BATS.
A Box Cox transformation is a transformation of non-normal dependent variables into a normal shape.

```{r TBATS train, echo=TRUE, message=FALSE, warning=FALSE}
# TBATS can take time to fit
TBATS_fit <- tbats(ts_humidity_train)

TBATS_for <- forecast(TBATS_fit, h=366)

#Plot foresting results
autoplot(TBATS_for) +
  ylab("Humidity") 

#Plot model + observed data
autoplot(humidity_ts) +
  autolayer(TBATS_for, series="TBATS",PI=FALSE)+
  ylab("Humidity") 

# Accuracy check
TBATS_scores <- accuracy(TBATS_for$mean,ts_humidity_test)
TBATS_scores
```

### Model 4: Neural Network Time Series Forecasts

There is a function in package `forecast` called `nnetar()` that will fit a feed-forward neural networks model to a time series.

A feed-forward neural network is fitted with lagged values of the series as inputs.
The inputs are for lags 1 to p, and lags s to sP where `s=frequency(y)`.
If xreg is provided, its columns are also used as inputs.
The network is trained for one-step forecasting.
Multi-step forecasts are computed recursively.

For non-seasonal data, the fitted model is denoted as an NNAR(p,k) model, where k is the number of hidden nodes.
This is analogous to an AR(p) model but with nonlinear functions.
For seasonal data, the fitted model is called an NNAR(p,P,k)[m] model, which is analogous to an ARIMA(p,0,0)(P,0,0)[s] model but with nonlinear functions.

```{r NNETAR, echo=TRUE, message=FALSE, warning=FALSE}

NN_fit <- nnetar(ts_humidity_train,
                 p=1,
                 P=0,
                 xreg=fourier(ts_humidity_train, K=c(2,10)))

#NN_for <- forecast(NN_fit, h=365) 
NN_for <- forecast(NN_fit, h=366,xreg=fourier(ts_humidity_train, 
                                          K=c(2,10),h=366))
#Plot foresting results
autoplot(NN_for) +
  ylab("Humidity") 

#Plot model + observed data
autoplot(humidity_ts) +
  autolayer(NN_for, series="Neural Network")+
  ylab("Humidity") 

#Accuracy check
NN_scores <- accuracy(NN_for$mean,ts_humidity_test)
NN_scores
```

```{r NNETAR, echo=TRUE, message=FALSE, warning=FALSE}
h_future <- 366
# Generate Fourier terms for training (if needed) and for forecasting 2010
fourier_train <- fourier(ts_load_train, K = K)
fourier_future <- fourier(ts_load_train, K = K, h = h_future)

# Ensure that your test weather vectors (for 2010) are numeric and have h_future entries.
ts_temp_test <- as.numeric(ts_temp_test)       # should have 366 values
ts_humidity_test <- as.numeric(ts_humidity_test)   # should have 366 values

# Create xreg matrices for training and forecasting
# (Assumes you have also created ts_temp_train and ts_humidity_train for training period)
xreg_train <- cbind(fourier_train, temp = ts_temp_train, hum = ts_humidity_train)
xreg_future <- cbind(fourier_future, temp = ts_temp_test, hum = ts_humidity_test)

# Fit the NNAR model on training data with external regressors
NN_fit <- nnetar(ts_load_train, p = 7, P = 1, xreg = xreg_train)

# Forecast for h_future days (2010)
NN_for <- forecast(NN_fit, xreg = xreg_future, h = h_future)

# Plot the forecast against observed (if you have the actual 2010 load data)
autoplot(NN_for) + ylab("Load") + ggtitle("Enhanced NNAR Forecast for 2010")

#Plot foresting results
autoplot(NN_for) +
  ylab("Load") +
  ggtitle("Enhanced NNAR Forecast for 2010")

#Plot model + observed data
autoplot(load_ts) +
  autolayer(NN_for, series="Neural Network",PI=FALSE)+
  ylab("Load") 

NN_scores <- accuracy(NN_for$mean,ts_load_test)
NN_scores
```

## Checking accuracy of the fo models

```{r}

#Model 1: STL + ETS
ETS_scores <- accuracy(ETS_fit$mean,ts_load_test)  

#Model 2: ARIMA + Fourier 
ARIMA_scores <- accuracy(ARIMA_Four_for$mean,ts_load_test)

# Model 3:  TBATS 
TBATS_scores <- accuracy(TBATS_for$mean,ts_load_test)

# Model 4:  Neural Network 
NN_scores <- accuracy(NN_for$mean,ts_load_test)


```

### Compare performance metrics

Now we will create a data frame that combines performance metrics for all the three models.
You can choose one metric to help you choose among models.

```{r}
#create data frame
scores <- as.data.frame(
  rbind(ETS_scores, ARIMA_scores, TBATS_scores, NN_scores)
  )
row.names(scores) <- c("STL+ETS", "ARIMA+Fourier","TBATS","NN")

#choose model with lowest RMSE
best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))                       
```

If you want generate a table to compare model accuracy and help visualize the results here is a suggestion on how to include a table on your Rmd report.
You can use the `kable_styling(latex_options="striped")` to highlight the model that leads to minimum RMSE.

```{r echo=FALSE, message=FALSE, warning=FALSE}
kbl(scores, 
      caption = "Forecast Accuracy for Daily Load",
      digits = array(5,ncol(scores))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(scores[,"RMSE"]))
```



### Plotting everything together

Here we will use autoplot() and autolayer() from package `ggplot2` to draw a particular plot for time series.
The function autolayer() takes a few main arguments.

-   **x** Forecast object produced by forecast() function.If forecasts were generated with another function you may need to point to the object either mean or forecast to get the values.\
-   **include** number of values from time series to include in plot.Default is all values.\
-   **PI** Logical flag indicating whether to plot prediction intervals.\
-   **series** Matches an unidentified forecast layer with a colored object on the plot.

```{r}
autoplot(load_ts) +
  autolayer(ETS_fit, PI=FALSE, series="STL+ETS") +
  autolayer(ARIMA_Four_for, PI=FALSE, series="ARIMA + Fourier") +
  autolayer(TBATS_for,PI=FALSE, series="TBATS") +
  autolayer(NN_for,PI=FALSE, series="NN") +
  xlab("Day") + ylab("Daily Load") +
  guides(colour=guide_legend(title="Forecast"))
```

If you want a closer look on last year just change the xlab range.

```{r}
autoplot(ts_load_test) +
  autolayer(ETS_fit, PI=FALSE, series="STL+ETS") +
  autolayer(ARIMA_Four_for, PI=FALSE, series="ARIMA + Fourier") +
  autolayer(TBATS_for,PI=FALSE, series="TBATS") +
  autolayer(NN_for,PI=FALSE, series="NN") +
  ylab("Daily Load") +
  guides(colour=guide_legend(title="Forecast"))
```
## Forecasting using TBATS

```{r TBATS Retrain, echo=TRUE, message=FALSE, warning=FALSE}
# TBATS can take time to fit
TBATS_fit <- tbats(load_ts)

TBATS_for <- forecast(TBATS_fit, h=59)

#Plot foresting results
autoplot(TBATS_for) +
  ylab("Load") 

#Plot model + observed data
autoplot(load_ts) +
  autolayer(TBATS_for, series="TBATS",PI=FALSE)+
  ylab("Load") 

TBATS_result <- as.data.frame(TBATS_for$mean)
print(TBATS_result)
```

## Forecasting using NN with K=c(2,4)
```{r}
NN_fit <- nnetar(humidity_ts,
                 p=1,
                 P=0,
                 xreg=fourier(humidity_ts, K=c(2,4)))

#NN_for <- forecast(NN_fit, h=365) 
NN_for <- forecast(NN_fit, h=59,xreg=fourier(humidity_ts, 
                                          K=c(2,4),h=59))

#Plot model + observed data
autoplot(humidity_ts) +
  autolayer(NN_for, series="Neural Network")+
  ylab("Humidity") 

NN_result <- as.data.frame(NN_for$mean)
print(NN_result)
```

```{r}
# Specify the file path where you want to save the CSV
file_path <- "Data/Humidity_Forecast.csv"

# Save the DataFrame to a CSV file
write.csv(NN_result, file = file_path, row.names = TRUE)
```
## Additional suggestions for the competition

-   Try including just one seasonal period, i.e., 7.
    Since we just have a few years of historical data, we may not have enough to model the influence of season of the year on demand.

-   You noticed that most of the models we learned can handle multiple seasonality as long as we add Fourier terms as regressors.
    Play with values of K.

-   You may use `xreg=` to incorporate other exogenous variable like temperature and humidity.

-   Try combining the models with a simple average of the forecasts and check the accuracy metrics.
    If that leads to good model, try changing the weights when calculating the average.
    
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
